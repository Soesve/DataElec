![Gif Back to the future](media/back-to-the-future.gif)
# Projet DataElec


## Sommaire
- Objectifs et organisation du projet
- Collecte des donn√©es (sources‚Äã, datalake)
- Pr√©paration des donn√©es (mod√©lisation‚Äã, traitement)
- Analyse‚Äã : data visualisation‚Äã
- Pour aller plus loin



## Objectifs et <br/>organisation du projet
- Objectifs du projet
- Organisation du projet


### Objectifs du projet
- Analyser la consommation √©lectrique en France pour identifier les √©l√©ments qui l'influencent : temp√©rature, type de clients, r√©gion, saisonnalit√© (jours de semaine, vacances)...
- Cette √©tude permettrait de guider des choix politiques : 
    - Pr√©vision de consommation √©lectrique et ajustement de la production
    - Identification de zones g√©ographiques particuli√®rement sensibles aux variations de temp√©rature (prioriser l'investissement sur l'isolation thermique des b√¢timents)
    - ...


### Organisation du projet
Github + Docker = ‚ù§Ô∏è
![Github](media/capture-github.png)


### Organisation du projet
Microsoft Teams pour les √©changes...
![Teams pour √©changer](media/capture-teams-publications.png)


### Organisation du projet
... et les partages de fichiers (hors github)
![Teams pour le partage de fichiers](media/capture-teams-fichiers.png)


### Organisation du projet 
Trello pour le suivi collaboratif des t√¢ches
![Trello](media/capture-trello.png)



## Collecte des donn√©es<br/>(sources‚Äã, datalake)
- Sources
- Import et stockage vers le datalake


### Les sources
- Open Data R√©seau Energies https://odre.opendatasoft.com/‚Äã
    - R√©seaux √ânergies r√©unit plusieurs acteurs de l'√©nergies (GRTgaz, RTE, Ter√©ga...) dans une d√©marche de transparence et de p√©dagogie √† l‚Äô√©gard des citoyens, des collectivit√©s territoriales et des acteurs √©conomiques...‚Äã
    - Donn√©es utilis√©es : Consommation et production par r√©gion, quotidien, annuel par type de client ou fili√®re de production...‚Äã


### Les sources
- INSEE https://www.insee.fr/‚Äã
    - L'Insee est une direction g√©n√©rale du minist√®re de l‚Äô√âconomie et des Finances implant√©e dans l'ensemble du territoire fran√ßais, ind√©pendante dont l'objectif est la conception, la production et la diffusion des statistiques publiques.‚Äã
    - Donn√©es utilis√©es : Population et type de logements par r√©gion, d√©partements, communes‚Äã


### Les sources
- Bulletin officiel de l'√©ducation nationale https://www.education.gouv.fr/‚Äã
    - Le Bulletin officiel de l'√©ducation nationale, de la jeunesse et des sports publie des actes administratifs : d√©crets, arr√™t√©s, notes de service, etc. ‚Äã
    - Donn√©es utilis√©es : dates des vacances scolaires par zone 


### Les sources
S√©lection des donn√©es √† r√©cup√©rer (sources, vocabulaire, type, mises √† jour...)
![Tableau des champs par source de donn√©es](media/tableau-sources-donnees.png)


### Import et stockage vers le datalake
On ne va pas se mentir, au tout d√©but, on a tout import√© en t√©l√©chargeant manuellement chaque fichier... mais ce n'√©tait pas id√©al pour partager le projet ou mettre √† jour les fichiers de consommation, production, de temp√©rature...


![Gif Back to the future](media/back-to-the-future-this-is-it.gif)
<br/>Puis vint Docker...


### Import et stockage vers le datalake
Depuis un script Python qui t√©l√©charge dans un dossier Datalake (utilis√© en volume docker)
![Datalake dans un dossier local](media/capture-flux-datalake.jpg)



## Pr√©paration des donn√©es<br/>(mod√©lisation‚Äã, traitement)
- Mod√©lisation du warehouse
- Traitement initial (V1)
- Traitement optimis√© (V2)


![Gif Back to the future](media/back-to-the-future-ready.gif)


### Mod√©lisation du warehouse
![Mod√©lisation du sch√©ma de donn√©es attendu dans le warehouse](media/schema-donnees.png)


### Traitement initial (V1)
En utilisant Talend sur des dossiers locaux
![Sch√©ma de l'architecture des traitements de donn√©es](media/schema-architecture-v01.jpg)


### Traitement initial (V1)
Exemple #1 d'un job Talend (jointure)
![Exemple de job sur Talend 01](media/capture-talend-02.png)


### Traitement initial (V1)
Exemple #2 d'un job Talend (d√©pivoter)
![Exemple de job sur Talend 02](media/capture-talend-01.png)


### Traitement initial (V1)
R√©sultat dans MySQL Workbench
![BDD dans MySqL Workbench](media/capture-mysql-workbench.png)


### Traitement initial (V1) 
Probl√©matiques rencontr√©es avec ce traitement : 
- Partage et collaboration difficile : 
    - Export/import de jobs Talend
    - Pas d'utilisation de Github
- Configuration de Talend assez lourde au regard du type de traitement n√©cessaire


![Gif Back to the future](media/back-to-the-future-amazing.gif)
<br/>Puis vint Docker...


### Traitement optimis√© (V2)
‚ù§Ô∏è Python + Docker + Github ‚ù§Ô∏è
![Sch√©ma de l'architecture du traitement optimis√© v2](media/schema-architecture-v02.jpg)


### Traitement optimis√© (V2)
Utilisation d'un fichier config.txt pour  y stocker les chemins des dossiers, les codes d'acc√®s √† la BDD...
![Import et jointure en python](media/code-configtxt.png)


### Traitement optimis√© (V2)
Utilisation d'un fichier config.txt pour  y stocker les chemins des dossiers, les codes d'acc√®s √† la BDD...
![Import et jointure en python](media/code-import-configtxt.png)


### Traitement optimis√© (V2)
L'exemple Talend #1 en Python
![Import et jointure en python](media/code-talend-01-en-python.png)


### Traitement optimis√© (V2)
L'exemple Talend #2 en Python
![d√©pivotage en python](media/code-talend-02-en-python.png)



## Data visualization
- Importation des donn√©es
- Dataviz


### Importation des donn√©es
Dans Qlik
![Sch√©ma des donn√©es apr√®s importation dans Qlik](media/capture-schema-donnees-qlik.png)


### Importation des donn√©es
Dans PowerBI
![Sch√©ma des donn√©es apr√®s importation dans PowerBI](media/capture-schema-donnees-powerbi.png)


### Dataviz
Premi√®re √©tape : faire un plan !
![Plan dataviz](media/capture-plan-dataviz.png)


### Dataviz
Dashboard - Qlik
![Dataviz Qlik - Ecran 01](media/capture-qlik-ecran-01.png)


### Dataviz
Dashboard - PowerBI
![Dataviz PowerBI - Ecran 01](media/capture-powerbi-ecran-01.png)


### Dataviz
Conso vs m√©t√©o - Qlik
![Dataviz Qlik - Ecran 02](media/capture-qlik-ecran-02.png)


### Dataviz
Conso vs m√©t√©o - PowerBI
![Dataviz PowerBI - Ecran 02](media/capture-powerbi-ecran-02.png)


### Dataviz
Conso vs jour de semaine - Qlik
![Dataviz Qlik - Ecran 03](media/capture-qlik-ecran-03.png)


### Dataviz
Conso vs jour de semaine - PowerBI
![Dataviz PowerBI - Ecran 01](media/capture-powerbi-ecran-03.png)


### Dataviz
Conso vs heure de la journ√©e - Qlik
![Dataviz Qlik - Ecran 04](media/capture-qlik-ecran-04.png)


### Dataviz
Conso vs heure de la journ√©e - PowerBI
![Dataviz PowerBI - Ecran 01](media/capture-powerbi-ecran-04.png)


### Dataviz
Conso vs type de client - Qlik
![Dataviz Qlik - Ecran 05](media/capture-qlik-ecran-05.png)


### Dataviz
Conso vs type de client - PowerBI
![Dataviz PowerBI - Ecran 01](media/capture-powerbi-ecran-05.png)


### Dataviz
Conso vs logements - Qlik
![Dataviz Qlik - Ecran 06](media/capture-qlik-ecran-06.png)


### Dataviz
Conso vs logements - PowerBI
![Dataviz PowerBI - Ecran 01](media/capture-powerbi-ecran-06.png)


### Dataviz
Production  - Qlik
![Dataviz Qlik - Ecran 07](media/capture-qlik-ecran-07.png)


### Dataviz
Production - PowerBI
![Dataviz PowerBI - Ecran 01](media/capture-powerbi-ecran-07.png)


### Dataviz
Imports/Exports - Qlik
![Dataviz Qlik - Ecran 08](media/capture-qlik-ecran-08.png)


### Dataviz
Imports/Exports - PowerBI
![Dataviz PowerBI - Ecran 01](media/capture-powerbi-ecran-08.png)



## Pour aller plus loin
- Retours d'exp√©riences
- Pistes d'optimisation


### Retours d'exp√©riences
- Utiliser tout de suite Docker + Github = ü´∂
- Qlik vs PowerBI : 
    - Importation des donn√©es : avantage √† PowerBI pour la configuration des cl√©s (et cl√©s secondaires)
    - Visuel cartes g√©ographiques : avantage √† Qlik pour la configuration du visuel
    - Visuel histogrammes : avantage √† Qlik pour le choix manuel de l'ordre des donn√©es
    - Calcul de la corr√©lation : avantage √† Qlik qui a une formule d√©di√©e
    - ...


### Pour aller plus loin
Optimisations : 
- Conditionner le script d'import √† la date de derni√®re mise √† jour du fichier en ligne vs celui en local
- Utiliser le cloud (voir diapos suivantes)


### Pour aller plus loin
Utiliser Google Cloud : Stocker le datalake dans un bucket
![Datalake dans un bucket Google Cloud](media/capture-bucket-datalake.png)


### Pour aller plus loin
Utiliser Google Cloud : Faire le traitement via DataProc et BigQuery
![Datalake dans un bucket Google Cloud](media/capture-bucket-datalake.png)



![Gif Back to the future](media/back-to-the-future-on-schedule.gif)
## Fin